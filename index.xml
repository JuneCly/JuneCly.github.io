<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chen LY</title>
    <link>https://JuneCly.github.io/</link>
    <description>Recent content on Chen LY</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 27 Aug 2022 13:36:02 +0800</lastBuildDate>
    
        <atom:link href="https://JuneCly.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>VGG</title>
      <link>https://JuneCly.github.io/post/vgg/</link>
      <pubDate>Sat, 27 Aug 2022 13:36:02 +0800</pubDate>
      
      <guid>https://JuneCly.github.io/post/vgg/</guid>
      
        <description>&lt;p&gt;VGG是由牛津大学视觉几何小组（&lt;strong&gt;V&lt;/strong&gt;isual &lt;strong&gt;G&lt;/strong&gt;eometry &lt;strong&gt;G&lt;/strong&gt;roup）提出的一种深层卷积网络，在2014年的ILSVRC比赛中获得了分类任务的亚军（同年该项冠军为GoogLeNet）和定位任务的冠军。&lt;/p&gt;
&lt;p&gt;论文：&lt;a href=&#34;https://arxiv.org/pdf/1409.1556.pdf&#34;&gt;Very Deep Convolutional Networks for Large-Scale Image Recognition&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;1-vgg网络架构&#34;&gt;1. VGG网络架构&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://JuneCly.github.io/image/VGG02.png&#34; alt=&#34;VGG convnet configuration&#34;&gt;&lt;/p&gt;
&lt;p&gt;VGG网络由5层卷积层，3层全连接层以及softmax输出层构成，层与层之间使用max pooling（最大池化）分开。作者根据具体卷积层的不同，共设计了6种网络结构，如上图所示，分别是A、A-LRN、B、C、D、E。这6种结构的网络深度从11层到19层。其中，D和E结构即是我们所熟知的VGG16和VGG19。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JuneCly.github.io/image/VGG01.jpg&#34; alt=&#34;VGG16&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图为VGG16的网络结构图。第1层卷积层由2个conv3-64组成，第2层卷积层由2个conv3-128组成，第3层卷积层由3个conv3-256组成，第4层卷积层由3个conv3-512组成，第5层卷积层由3个conv3-512组成，后接3个全连接层，前两个FC输出通道数为4096，后1个FC输出通道数为1000，最后经过softmax。共计16层。&lt;/p&gt;
&lt;h2 id=&#34;2-网络特点&#34;&gt;2. 网络特点&lt;/h2&gt;
&lt;h3 id=&#34;21-结构简单&#34;&gt;2.1 结构简单&lt;/h3&gt;
&lt;p&gt;作者在文中提出的6种网络结构虽在细节上有所不同，但VGG总体的网络结构保持一致，即5卷积+3全连接+softmax，并且层与层之间使用maxpool分开。所有隐层的激活函数均为ReLU。&lt;/p&gt;
&lt;h3 id=&#34;22-小卷积核&#34;&gt;2.2 小卷积核&lt;/h3&gt;
&lt;p&gt;VGG使用多个小卷积核（3x3）来代替一个较大的卷积层。例如，2个3x3的卷积层相当于1个5x5卷积，3个3x3卷积相当于1个7x7卷积。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JuneCly.github.io/image/VGG03.png&#34; alt=&#34;感受野&#34;&gt;&lt;/p&gt;
&lt;p&gt;使用小卷积核有两点好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减少模型参数量&lt;/li&gt;
&lt;li&gt;因卷积核变小二导致的层数增加，可以增加模型的非线性表达能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;23-小池化核&#34;&gt;2.3 小池化核&lt;/h3&gt;
&lt;p&gt;相比于AlexNet的3x3的池化核，VGG全部采用2x2的池化核。&lt;/p&gt;
&lt;h3 id=&#34;24-通道数更多&#34;&gt;2.4 通道数更多&lt;/h3&gt;
&lt;p&gt;更多的通道数可以表示更多的图像特征，VGG网络每个卷积层都对通道数进行了翻倍操作，直至增大到512个通道数。这样就可以提取出更多的信息。&lt;/p&gt;
&lt;h3 id=&#34;25-全连接转卷积&#34;&gt;2.5 全连接转卷积&lt;/h3&gt;
&lt;p&gt;VGG在&lt;strong&gt;测试阶段&lt;/strong&gt;将训练阶段的3个全连接层替换为3个卷积层，这样做的优点是可以处理任意大小尺寸的图片输入，并减少特征位置对分类的影响。（注：这个特点是作者参考了OverFeat的工作思路。）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://JuneCly.github.io/image/VGG04.png&#34; alt=&#34;测试阶段全连接转卷积&#34;&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AlexNet</title>
      <link>https://JuneCly.github.io/post/alexnet/</link>
      <pubDate>Mon, 22 Aug 2022 15:57:49 +0800</pubDate>
      
      <guid>https://JuneCly.github.io/post/alexnet/</guid>
      
        <description>&lt;p&gt;AlexNet在2012的ImageNet的竞赛中获得了冠军，该模型由Hintom和他的学生Alex Krizhevsky等人提出。 AlexNet由5个卷积层和3个全连接层构成，并首次使用ReLU、LRN、Dropout等技巧来提高网络的准确率。&lt;/p&gt;
&lt;p&gt;论文：&lt;a href=&#34;http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf&#34;&gt;AlexNet&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;alexnet架构&#34;&gt;AlexNet架构&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://JuneCly.github.io/image/AlexNet01.png&#34; alt=&#34;AlexNet架构&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;tricks&#34;&gt;Tricks&lt;/h2&gt;
&lt;p&gt;AlexNet应用的一些特殊的方法（按重要性进行排序）&lt;/p&gt;
&lt;h3 id=&#34;relu&#34;&gt;ReLU&lt;/h3&gt;
&lt;p&gt;AlexNet首次使用ReLU函数代替sigmoid和Tanh作为激活函数，这是因为相比于后两个函数，ReLU可以更好的解决梯度消失的问题。当ReLU函数的输入大于0时直接返回原值，输入小于0时则返回0。这样既可以利用正输入的梯度为1这个特点解决梯度消失问题，也可以利用负输入的输出为0这一特性，增加模型的稀疏性表示，进而加速并简化模型。（需要注意的是，ReLU常作为CNN的激活函数，但通常情况下并不适合作为RNN的激活函数）&lt;/p&gt;
&lt;h3 id=&#34;多gpu训练&#34;&gt;多GPU训练&lt;/h3&gt;
&lt;p&gt;由于GTX 580 GPU只有3GB的内存，因此将AlexNet网络分布在两块GPU上进行训练。需要额外注意的是，在训练时，GPU只在某些特定的层上进行通信，比如第3层的核会将第2层的所有核映射作为输入，第4层的核只将位于同一GPU上的第3层的核映射作为输入（这一点在网络架构图中可以看出）。&lt;/p&gt;
&lt;h3 id=&#34;lrn-局部响应归一化&#34;&gt;LRN (局部响应归一化)&lt;/h3&gt;
&lt;p&gt;局部响应归一化 (Local Response Normalization) 通过模拟生物医学中的“侧抑制”（被激活的神经元会抑制周围的神经元）来实现局部抑制，增强模型的泛化能力。（注：现在LRN已经逐渐被BN所取代）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;归一化的优点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加快收敛速度&lt;/li&gt;
&lt;li&gt;提高模型精度&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;重叠池化&#34;&gt;重叠池化&lt;/h3&gt;
&lt;p&gt;通常池化的窗口大小z与步长s相等，因此池化作用的区域不存在重叠的部分。但重叠池化令z&amp;gt;s，使得池化区域之间存在重叠的部分。AlexNet这篇论文指出，采用重叠池化的模型更不容易过拟合。&lt;/p&gt;
&lt;h2 id=&#34;减少过拟合&#34;&gt;减少过拟合&lt;/h2&gt;
&lt;p&gt;AlexNet主要使用两种方法来克服过拟合。&lt;/p&gt;
&lt;h3 id=&#34;数据增强&#34;&gt;数据增强&lt;/h3&gt;
&lt;p&gt;AlexNet用两种方式实现数据增强。因这两种方式都是由原始图像经非常少的计算量产生变换得到的图像，因此无需存储在硬盘上。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;随机裁剪、水平翻转&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;改变训练图像的RGB通道的强度&lt;/strong&gt;：对RGB像素值集合执行PCA，并对主成分做一个标准差为0.1的高斯扰动。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dropout&#34;&gt;Dropout&lt;/h3&gt;
&lt;p&gt;在训练过程中以p=0.5的概率对每个隐层神经元的输出设为0，以此丢弃部分神经元。这些被丢弃的神经元将不再进行前向传播并且不参与反向传播。采用droput方法可以避免过拟合。&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Test</title>
      <link>https://JuneCly.github.io/post/test/</link>
      <pubDate>Mon, 15 Aug 2022 15:33:51 +0800</pubDate>
      
      <guid>https://JuneCly.github.io/post/test/</guid>
      
        <description>&lt;p&gt;测试&lt;/p&gt;
&lt;h2 id=&#34;paragraph-and-line-breaks&#34;&gt;Paragraph and line breaks&lt;/h2&gt;
&lt;p&gt;A paragraph is simply one or more consecutive lines of text. In markdown source code, paragraphs are separated by more than one blank lines. In Typora, you only need to press &lt;code&gt;Return&lt;/code&gt; to create a new paragraph.&lt;/p&gt;
&lt;p&gt;Press &lt;code&gt;Shift&lt;/code&gt; + &lt;code&gt;Return&lt;/code&gt; to create a single line break. However, most markdown parser will ignore single line break, to make other markdown parsers recognize your line break, you can leave two whitespace at the end of the line, or insert &lt;code&gt;&amp;lt;br/&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;headers&#34;&gt;Headers&lt;/h2&gt;
&lt;p&gt;Headers use 1-6 hash characters at the start of the line, corresponding to header levels 1-6. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# This is an H1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;## This is an H2
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;###### This is an H6
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In typora, input ‘#’s followed by title content, and press &lt;code&gt;Return&lt;/code&gt; key will create a header.&lt;/p&gt;
&lt;h2 id=&#34;blockquotes&#34;&gt;Blockquotes&lt;/h2&gt;
&lt;p&gt;Markdown uses email-style &amp;gt; characters for block quoting. They are presented as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is a blockquote with two paragraphs. This is first paragraph.&lt;/p&gt;
&lt;p&gt;This is second pragraph.Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.&lt;/p&gt;
&lt;p&gt;This is another blockquote with one paragraph. There is three empty line to seperate two blockquote.&lt;/p&gt;
&lt;p&gt;这是一段中文测试。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In typora, just input ‘&amp;gt;’ followed by quote contents a block quote is  generated. Typora will insert proper ‘&amp;gt;’ or line break for you. Block quote inside anther block quote is allowed by adding additional levels of ‘&amp;gt;’.&lt;/p&gt;
&lt;h2 id=&#34;lists&#34;&gt;Lists&lt;/h2&gt;
&lt;p&gt;Input &lt;code&gt;* list item 1&lt;/code&gt; will create an un-ordered list, the &lt;code&gt;*&lt;/code&gt; symbol can be replace with &lt;code&gt;+&lt;/code&gt; or &lt;code&gt;-&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Input &lt;code&gt;1. list item 1&lt;/code&gt; will create an ordered list, their markdown source code is like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Red&lt;/li&gt;
&lt;li&gt;Green&lt;/li&gt;
&lt;li&gt;Blue&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Red&lt;/li&gt;
&lt;li&gt;Green&lt;/li&gt;
&lt;li&gt;Blue&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;task-list&#34;&gt;Task List&lt;/h2&gt;
&lt;p&gt;Task lists are lists with items marked as either &lt;code&gt;[ ]&lt;/code&gt; or &lt;code&gt;[x]&lt;/code&gt; (incomplete or complete). For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; a task list item&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; list syntax required&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; normal &lt;strong&gt;formatting&lt;/strong&gt;, @mentions, #1234 refs&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; incomplete&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; completed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can change the complete/incomplete state by click the checkbox before the item.&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
